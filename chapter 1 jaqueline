%
% File: CHAP-01.tex
% Author: Amit Tyagi
% Description: Introduction to the Anomaly Detection Research.
%
\let\textcircled=\pgftextcircled
\chapter{Introduction}
\label{chap:intro}

\initial{T}here are two kinds of people in the world, one who want to be different (intentionally or unintentionally) in all walks of life than rest of the masses and the second who don't. 
However, the first kind of people is not found as often as the second kind. For example: Imagine a spiritual leader in India preaching in front of tens of thousands of people. If one statistically analyzes this event, a long list of similar features can be found which would be shared by the audience but very few similarities between the audience and the preacher. What it tells us is that we human beings are quite interested in the anomalous behavior or characteristics of a person, thing or an event. The anomalous characteristics of the preacher could be his world view which deviates up to great extent than that of the audience and this deviation in worldview makes the preacher an interesting person for the audience because it helps audience to see the world from an unusual perspective and eventually experience the paradigm shift in their understanding of certain phenomenon. These anomalous characteristics can also be positive or negative in nature but in both the cases, they attract the attention towards them. The importance of these is well described philosophically in \textit{The Black Swan: The impact of highly improbable} by \citep{taleb2007black} and in \textit{Anomaly Detection in Large Datasets} by \citep{AnomalyDetectionPhD2014} where an event like seeing a black swan has been defined as an anomalous event with three characteristics i.e., it is very rare, retrospectively unpredictable and has an extreme impact.

In the computer science and statistics, anomalies are the abruptly unusual and surprising patterns in the observed data which are often unexpected to occur. It is one of the important aspects 
of data mining to identify, understand and predict the anomalies. The term 'Anomaly' is often used interchangeably with the term 'Outlier'. As per Hawkins: "an outlier is an observation, which
deviates so much from other observations as to arouse suspicions that it was generated by a different mechanism" \citep{GVK02435757X}. However, I observe a slight difference between an outlier and
anomaly which, however, depends on the application context: an outlier is a data point which is quite distant from the mean or median (or statistical measures) of the underlying distribution of 
the data but still can be encircled within the legitimacy of the system while an anomaly is a data point which does not conform with the stochastic process which has generated the underlying 
distribution. Anomaly detection provides with the possibilities to extract the valuable information from the data which can be used in various kinds of applications like Intrusion detection systems,
fraud detection in credit cards usage, fault detection in complex systems, Insider Trading detection, Insurance claim fraud detection etc. Historically, anomaly detection has played an important 
role in the discovery of the new theories which includes the discovery of Neptune, El Ni\~no\textendash Southern Oscillation and the use of fluoride in toothpaste \citep{AnomalyDetTutorial}.

\section{What is an Anomaly?}
		An anomaly is a pattern in the data which do not conform to the expected behavior. Anomaly, depending on the context is also known by several other names such as outlier, change point,
		discordant, fault, deviant, fraud, failure, abnormality, novelty etc. In most of the situation, it becomes very important to detect these anomalies e.g., in the case of a credit card fraud, 
		an intrusion to the security system or a sudden drop in the health of the system etc. The figure below depicts the intuition of anomaly as opposed to the normal data.

		\begin{figure}[H]
			\centering
			\includegraphics[width=1.0\textwidth, clip=true, keepaspectratio=true]{FIG-01/\detokenize{anomalies}}
			\caption{Anomalies or Outliers}
		\end{figure}

		There are three clusters in the figure above, which consists of most of the data point under certain regulation (e.g., distance from the centroid). Data points which fall beyond the boundaries
		of all three clusters do not follow normal behavior and hence are considered as outliers or anomalies. In most of the scenarios, data is generated by certain processes and when these processes
		behave unexpectedly then they result in anomalous data. This anomalous data often possess certain attributes of the generating processes and after careful inspection of the changes in the attributes
		of the generating processes, it is easy to get an insight of the root cause of the anomaly.

\section{Types of Anomaly}
		There have been many attempts to categorize the anomaly detection problems like by \citep{Hodge:2004:SOD:1028911.1028946}, by \citep{Agyemang:2006:CSN:1609942.1609946},
		by \citep{Chandola:2009:ADS:1541880.1541882} and by \citep{6684530}  but the work done by \citep{Chandola:2009:ADS:1541880.1541882} provides a very comprehensive, 
		modern and detailed overview of the anomaly detection domain. This section and subsequent sections in this chapter will be mainly based on the work done by \citep{Chandola:2009:ADS:1541880.1541882}.
		In order to detect anomalies in a particular application, a data model is prepared. This data model represents the normal behavior of the system. When a data point deviates from this normal model
		and goes beyond a certain threshold then it is declared as an outlier or anomaly. However, some applications, as opposed to a single data point, require a sequence of multiple data points to detect
		the anomalous behavior of the system e.g., in credit card fraud a particular sequence of certain activities reflects an abnormal behavior. So based on the nature of the application, anomalies are classified 
		into three types \textit{point anomalies}, \textit{collective anomalies} and \textit{contextual anomalies} \citep{Chandola:2009:ADS:1541880.1541882}.

		\subsection{Point Anomalies}
			If a single data point deviates in nature from the norm, then this data point is known as \textit{point anomaly}. Point anomalies are the simplest form of anomalies. Most of the algorithms
			for anomaly detection focus on detecting point anomalies. In the figure below, a 2-dimensional dataset is visualized where blue data points are in the normal region and red data points fall beyond
			the region which is defined as normal by some algorithm. Hence, red data points are declared as point anomalies.  

			\begin{figure}[H]
				\centering
				\includegraphics[width=1.0\textwidth, clip=true, keepaspectratio=true]{FIG-01/\detokenize{pointAnomaly}}
				\caption{Point Anomalies}
			\end{figure}

		\subsection{Collective Anomalies}
			If a sequence of data points is considered to be anomalous with respect to rest of the data set, then this particular sequence is considered to be a \textit{collective anomaly}. However, a single
			data instance in the anomalous sequence does not necessarily need to be an anomaly in itself. This kind of anomalies are very complex in nature and hence are very difficult to detect. In the collective anomaly
			detection problem formulation, data instances are considered to have certain relation among them. In the figure below, red data points collectively are considered as anomalous sequences however each individual
			red data point may not be an anomaly by itself. Collective anomaly problem is well investigated by Noble et. al in graph data \citep{noble2003graph}, by \citep{warrender1999detecting} in sequence data 
			and by \citep{Shekhar:2001:DGS:502512.502567} in spatial data.

			\begin{figure}[H]
				\centering
				\includegraphics[width=1.0\textwidth, clip=true, keepaspectratio=true]{FIG-01/\detokenize{collectiveAnomaly}}
				\caption{Collective Anomalies}
			\end{figure}
		
		\subsection{Contextual Anomalies}
			A data instance is considered as \textit{contextual anomaly} only with respect to a specific context but not otherwise. The contextual anomaly is also known as \textit{conditional anomaly} \citep{4138201}. 
			Contextual anomalies are the most frequently occurring anomalies in the real world data processing. In modeling a contextual anomaly problem, a set of contextual attributes is included in addition to 
			the set of behavioral attributes. For example, if we are measuring the number of sessions generated by the all the users for an android application over time, then \textit{time} here is a contextual 
			attribute and the \textit{number of sessions} is a behavioral attribute. In the figure below, a yearly rainfall is visualized over time. The red circled part of the time-series with respect to its 
			behavioral attribute value is not an anomaly but if we add the contextual attribute i.e., time (in this case) then it becomes an anomaly as the behavioral value (amount of rainfall) is not normal in 
			the month of June based on the historical data. Contextual anomaly problem is most commonly modeled in the datasets where the time (i.e., time-series) \citep{Weigend95nonlineargated} 
			\citep{Salvador:2005:LSR:1105622.1105629} and location (i.e., spatial data) \citep{doi:10.1137/1.9781611972764.71} \citep{Shekhar:2001:DGS:502512.502567} act as contextual attributes.

			\begin{figure}[H]
				\centering
				\includegraphics[width=1.0\textwidth, clip=true, keepaspectratio=true]{FIG-01/\detokenize{contextualAnomaly}}
				\caption{Contextual Anomalies}
			\end{figure}
			
			We have seen that for the point anomalies and collective anomalies the availability of the contextual information is not necessary. In contrast, contextual information is required for the modeling of contextual 
			anomaly detection problem. However, if the contextual attributes are available, then the point --- or collective --- anomaly detection problems can also be formulated as contextual anomaly detection problems by
			including contextual attributes in the modeling parameters.

\section{Taxonomy of Anomaly Detection Approaches}
		In general, anomaly detection approach adoption depends upon the nature of data. However, there are so many factors in deciding upon a good anomaly detection approach e.g., number of features, types of features 
		(numerical, categorical, mixed), labels etc. but among all data labels are the most important factor in decision making i.e., whether the data points are labeled or not w.r.t their anomaly status. There are different 
		situations: normal, anomalous labels or only normal labels or no labels at all. So depending upon the type of labeling, anomaly detection techniques can be classified into the three types i.e.,
		\textit{Supervised Anomaly Detection}, \textit{Semi-supervised Anomaly Detection} and \textit{Unsupervised Anomaly Detection}.

		\subsection{Supervised Anomaly Detection}
			In supervised approaches, the labels for normal and anomalous data points are available (which are usually annotated manually by a human) and the training models are built around these two classes normal and
			anomalous. Each new data points is compared to the training model (classifier) to figure out if the new incoming data point belongs to the normal or anomalous class. There is only one difference 
			to the supervised machine learning is the ratio of a number of labels in different classes. In supervised anomaly detection, obtaining a sufficient amount of anomalous labels is very difficult which results 
			in unbalanced training data and eventually affects the ability of the classifier to detect the unseen data as anomaly. However, there are some contribution from \citep{Chawla:2004:ESI:1007730.1007733} 
			\citep{Joshi01miningneedles} \citep{Joshi:2002:PRC:775047.775092} towards addressing this problem in supervised anomaly detection. Some classifiers like Support Vector Machine \citep{Scholkopf:2001:LKS:559923}, 
			Bayesian Networks \citep{Pearl:1988:PRI:52121} and Artificial Neural networks \citep{Mehrotra:1996:EAN:241682} are also used to address this problem. Anomalies are new and unseen data points which generally 
			have different features and hence can not be put together in one class as usually done in most supervised anomaly detection algorithms. This assumption might work in a specific scenario but usually, this is 
			not the case. In addition to that, obtaining a label for the data point which has not yet seen is almost impossible. Due to these reasons, supervised technique-based approaches are rarely used for anomaly 
			detection \citep{AnomalyDetectionPhD2014}.

			\begin{figure}[H]
				\centering
				\includegraphics[width=1.0\textwidth, clip=true, keepaspectratio=true]{FIG-01/\detokenize{supervised}}
				\caption{Supervised Anomaly Detection}
			\end{figure}

		\subsection{Unsupervised Anomaly Detection}
			In Unsupervised Approaches, data does not have any labeling information and consists of both normal and anomalous data instances. Therefore, there is no training phase involved in modeling the anomaly detection 
			problem. Unsupervised algorithms often detect anomalies based on the hidden structures in the unlabeled data. These hidden structures are often inferred by distance information. Unsupervised based approaches 
			are so far the best performing and most sophisticated anomaly detection techniques. In the world of big data, where tons of data is accumulated in the data warehouses every day, it is almost impossible to label this much amount
			of data. Hence, unsupervised based techniques are the most favorable ones in these scenarios. These techniques rely on the underlying assumption that the normal events are more frequent than the anomalous events 
			in test data set and features of anomalous events deviate from the norm. If these assumptions do not hold then it will result in a high false positive rate. 
			
			\begin{figure}[H]
				\centering
				\includegraphics[width=1.0\textwidth, clip=true, keepaspectratio=true]{FIG-01/\detokenize{unsupervised}}
				\caption{Unsupervised Anomaly Detection}
			\end{figure}

		\subsection{Semi-supervised Anomaly Detection}
			In Semi-supervised approaches in contrast to supervised approaches, the labels are only available for normal class hence the model is built merely based upon the set of normal instances. In these approaches, 
			the anomalous class does not need to be known in advance. Therefore, it widens the applicability of semi-supervised solutions and makes them more diverse than supervised techniques. A typical scenario for 
			semi-supervised anomaly detection application is quality control in a manufacturing industry where the normal behavior (i.e., a product with acceptable features) is learned from the training data set (normal class)
			and anomalies (products which do not meet the quality criteria) are detected. These anomalous products might have some unseen features and could be difficult to model for a supervised technique based algorithm. 
			Another example could be fault detection in space crafts\citep{Fujimaki:2005:ASA:1081870.1081917}, an anomalous scenario which could yield into an accident, is not easy to model as it could be most likely an unseen
			scenario hence testing against the normal class model to identify anomalous events is more desirable in this kind of scenarios. There are many well-known algorithms based on semi-supervised techniques, for example,
			One-class SVM by Sch{\"o}lkopf et al. \citep{Scholkopf:1999:SVM:3009657.3009740} which decides whether a data instance does belong to the normal class (learned a class in training phase) or not.
			
			\begin{figure}[H]
				\centering
				\includegraphics[width=1.0\textwidth, clip=true, keepaspectratio=true]{FIG-01/\detokenize{semi-supervised}}
				\caption{Semi-supervised Anomaly Detection}
			\end{figure}
		
\section{Output of Anomaly Detection Algorithm}
			The output of an anomaly detection algorithm is a very important topic. Some of the algorithms, especially supervised learning based approaches, yield \textit{labels} as output. Which is simply an annotation of 
			a data point as \textit{Normal} or \textit{Anomalous}. However, semi-supervised and unsupervised algorithms result in a numerical output also known as \textit{Anomaly Score} which can be interpreted
			as the outlierness of the anomalous data instance. In contrast to labels, anomaly scores allow an analyst to set the outlierness threshold to select the most relevant set of anomalies rather than a fixed set of anomalous 
			instances. Anomaly scores can also be interpreted much better as compared to labels.
	
\section{Applications of Anomaly Detection}
			Anomaly detection is widely used in many practical applications nowadays. In this section, some of the most important use cases of anomaly detection are listed \citep{Chandola:2009:ADS:1541880.1541882} 
			\citep{Hodge:2004:SOD:1028911.1028946}. One of the most famous use cases is to detect criminal activities also known as \textit{Fraud Detection} wherein anomaly detection can be used to detect various kinds of 
			fraudulent activities e.g., fraudulent credit card usage, mobile phone frauds, insurance claim frauds, loan applications processing and internal trading in stock markets. In network security, anomaly detection
			is used to detect malicious activities also known as intrusions. Intrusion detection systems (IDS) are used to monitor activities in networks. There are two kinds of intrusion detection systems i.e., Host-based
			IDS \& Network IDS (NIDS) \citep{Denning:1987:IM:22853.22862}. In medical and public health domain, anomaly detection is used in various scenarios e.g., in Electrocardiograms (ECG), Electroencephalograms (EEG)
			\citep{Lin:2005:AMF:1078022.1078134}. In image processing, anomaly detection is used to find interesting patterns like motion detection (video surveillance), in satellite image processing \citep{theiler2003resampling} 
			\citep{10.2307/2670109}, in digit recognition \citep{Cun:1990:HDR:109230.109279}, in spectral imaging \citep{davy2002detection} \citep{hazel2000multivariate}, medical image analysis (abnormal cells or tumour detection 
			in MRI, CT scans) \citep{AnomalyDetectionPhD2014}. In industries, anomaly detection is used detecting faults or damages in the mechanical units (motors, generators, pipelines, turbines, engines etc.), detecting 
			structural damage (e.g., cracks in beams). In text data, anomaly detection can be used to detect news, events, new entities etc. Now a days, a most interesting application of anomalies in text data is to do a fact 
			check of new articles. Other application includes netwrok performance, pharmaceutical research, document forensic \citep{conf/icdar/BeusekomS11}, sensor networks, speech recognition \citep{emamian2000robust}, 
			astronomical data \citep{Rebbapragada2009}, in customer relationship data (CRM) data \citep{he2004mining}, in traffic monitoring \citep{Shekhar:2001:DGS:502512.502567}, in robotic behavior \citep{Crook01arobot} etc.


\section{The Contribution of the Thesis}
	
	In order to solve the problem of anomaly detection in Unified LEOtrace Data stream (ULD)\footnotemark the Probabilistic \& Statistical based technique (more specifically Bayesian-based approach) has been used. There is a related 
	work by \citep{2007arXiv0710.3742P} 'Bayesian Online Changepoint Detection'. In this work, the author proposed an approach to for change point detection in online data. The research work in this thesis is based upon the work by 
	\citep{2007arXiv0710.3742P} . There are number of contributions which are given as follows: 
	
	\begin{itemize}
	
	\item I have adapted the work the agorithm on 'Bayesian Online Changepoint Detection' to solve the problem of anomaly detection. The original algorithm is designed to detect
		  the changepoint in the data streams where a change point occurs as a result due to the change in the stochastic process which generates the data stream. However, a change 
		  in generative parameters does not necessarily yield to an anomaly in the data stream but a potential candidate to be anomaly. An additional scoring system assign an anomaly
		  score to each data point to leave out the change points which do not yield to an anomaly.

	\item I also applied the adapted algorithm to work on a number of datasets i.e., A synthetic dataset, well-log dataset (also studied by \citep{2007arXiv0710.3742P}) and a corporate 
	      data set in order to judge the robustness of the proposed approach using comparative analysis. 

	\item In addition to that, I propose an Anomaly Detection Framework which is illustrated in the figure below. The framework consists of three main 
		  components namely Anomaly Detector, Human Annotation and Machine Learning component. The data stream is consumed by Anomaly Detector components and it automatically 
		  annotates the data instances as normal or anomalous. A human annotator validates the labels assigned by Anomaly detector and labels them as true or false detection. 
		  All of the annotated data instances are stored in the database and used as training examples to train the machine learning model, which provides a feedback to anomaly 
		  detector every time when a new data instance is observed. As the number of annotated anomalous instances grow over time the accuracy of detection is expected to grow 
		  accordingly. The research focus of this master thesis is on anomaly detector component only.
	\end{itemize}

	\footnotetext{The data set used in this research work is called Unified LEOtrace\textsuperscript{\textregistered} Dataset 
              (ULD) in business context of GfK. The Unified LEOtrace\textsuperscript{\textregistered} Dataset combines data
			  from Microsoft Windows devices and mobile devices. The detailed description of the data set is given in \textit{chapter 4}.}

		\begin{figure}[H]
			\centering
			\includegraphics[width=0.9\textwidth, clip=true, keepaspectratio=true]{FIG-01/\detokenize{framework}}
			\caption{Anomaly Detection Framework}
		\end{figure}

\section{Thesis Organization}
	This report is organized in the following manner. Chapter 2 consists of the motivation for this research and the problem statement. Chapter 3 walks through the related work on the topic. Chapter 4 describes the 
	dataset which has been used in this research work. Chapter 5 is focused on the methodology used to solve the problem of anomaly detection while keeping the original objectives in mind. Chapter 6 discusses the 
	evaluation and the results of the proposed solution. Finally, Chapter 7 concludes and summarizes the research work carried out in this thesis.

%=========================================================
